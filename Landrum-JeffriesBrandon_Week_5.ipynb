{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "165166dd",
   "metadata": {},
   "source": [
    "# DS Automation Assignment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c195af74",
   "metadata": {},
   "source": [
    "Using our prepared churn data from week 2:\n",
    "- use pycaret to find an ML algorithm that performs best on the data\n",
    "    - Choose a metric you think is best to use for finding the best model; by default, it is accuracy but it could be AUC, precision, recall, etc. The week 3 FTE has some information on these different metrics.\n",
    "- save the model to disk\n",
    "- create a Python script/file/module with a function that takes a pandas dataframe as an input and returns the probability of churn for each row in the dataframe\n",
    "    - your Python file/function should print out the predictions for new data (new_churn_data.csv)\n",
    "    - the true values for the new data are [1, 0, 0, 1, 0] if you're interested\n",
    "- test your Python module and function with the new data, new_churn_data.csv\n",
    "- write a short summary of the process and results at the end of this notebook\n",
    "- upload this Jupyter Notebook and Python file to a Github repository, and turn in a link to the repository in the week 5 assignment dropbox\n",
    "\n",
    "*Optional* challenges:\n",
    "- return the probability of churn for each new prediction, and the percentile where that prediction is in the distribution of probability predictions from the training dataset (e.g. a high probability of churn like 0.78 might be at the 90th percentile)\n",
    "- use other autoML packages, such as TPOT, H2O, MLBox, etc, and compare performance and features with pycaret\n",
    "- create a class in your Python module to hold the functions that you created\n",
    "- accept user input to specify a file using a tool such as Python's `input()` function, the `click` package for command-line arguments, or a GUI\n",
    "- Use the unmodified churn data (new_unmodified_churn_data.csv) in your Python script. This will require adding the same preprocessing steps from week 2 since this data is like the original unmodified dataset from week 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "476ed965",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieving notices: ...working... DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): repo.anaconda.com:443\n",
      "DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): repo.anaconda.com:443\n",
      "DEBUG:urllib3.connectionpool:https://repo.anaconda.com:443 \"GET /pkgs/r/notices.json HTTP/1.1\" 404 None\n",
      "DEBUG:urllib3.connectionpool:https://repo.anaconda.com:443 \"GET /pkgs/main/notices.json HTTP/1.1\" 404 None\n",
      "done\n",
      "Collecting package metadata (current_repodata.json): / DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): repo.anaconda.com:443\n",
      "DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): repo.anaconda.com:443\n",
      "DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): repo.anaconda.com:443\n",
      "DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): repo.anaconda.com:443\n",
      "DEBUG:urllib3.connectionpool:https://repo.anaconda.com:443 \"GET /pkgs/r/noarch/current_repodata.json HTTP/1.1\" 304 0\n",
      "DEBUG:urllib3.connectionpool:https://repo.anaconda.com:443 \"GET /pkgs/r/osx-arm64/current_repodata.json HTTP/1.1\" 304 0\n",
      "DEBUG:urllib3.connectionpool:https://repo.anaconda.com:443 \"GET /pkgs/main/noarch/current_repodata.json HTTP/1.1\" 200 None\n",
      "- DEBUG:urllib3.connectionpool:https://repo.anaconda.com:443 \"GET /pkgs/main/osx-arm64/current_repodata.json HTTP/1.1\" 200 None\n",
      "done\n",
      "Solving environment: / \n",
      "The environment is inconsistent, please check the package plan carefully\n",
      "The following packages are causing the inconsistency:\n",
      "\n",
      "  - defaults/noarch::tifffile==2021.7.2=pyhd3eb1b0_2\n",
      "  - conda-forge/noarch::imagehash==4.3.1=pyhd8ed1ab_0\n",
      "  - defaults/osx-arm64::scikit-image==0.20.0=py311h313beb8_0\n",
      "  - defaults/osx-arm64::pyerfa==2.0.0=py311h80987f9_0\n",
      "  - defaults/osx-arm64::numba==0.57.0=py311h7aedaa7_0\n",
      "  - defaults/osx-arm64::matplotlib-base==3.7.1=py311h7aedaa7_1\n",
      "  - defaults/osx-arm64::pywavelets==1.4.1=py311h80987f9_0\n",
      "  - defaults/osx-arm64::panel==1.2.1=py311hca03da5_0\n",
      "  - defaults/osx-arm64::bokeh==3.2.1=py311hb6e6a13_0\n",
      "  - defaults/osx-arm64::pyarrow==11.0.0=py311h7575258_0\n",
      "  - conda-forge/noarch::seaborn-base==0.12.2=pyhd8ed1ab_0\n",
      "  - defaults/osx-arm64::patsy==0.5.3=py311hca03da5_0\n",
      "  - defaults/osx-arm64::anaconda-catalogs==0.2.0=py311hca03da5_0\n",
      "  - defaults/osx-arm64::pytables==3.8.0=py311he239255_2\n",
      "  - defaults/osx-arm64::matplotlib==3.7.1=py311hca03da5_1\n",
      "  - defaults/osx-arm64::transformers==4.29.2=py311hca03da5_0\n",
      "  - defaults/osx-arm64::datashape==0.5.4=py311hca03da5_1\n",
      "  - defaults/osx-arm64::numexpr==2.8.4=py311h6dc990b_1\n",
      "  - defaults/osx-arm64::dask==2023.6.0=py311hca03da5_0\n",
      "  - defaults/osx-arm64::datasets==2.12.0=py311hca03da5_0\n",
      "  - conda-forge/noarch::phik==0.11.2=pyhd8ed1ab_0\n",
      "  - defaults/osx-arm64::numpy==1.24.3=py311hb57d4eb_0\n",
      "  - defaults/osx-arm64::imagecodecs==2021.8.26=py311haa897ea_2\n",
      "  - defaults/noarch::sacremoses==0.0.43=pyhd3eb1b0_0\n",
      "  - defaults/osx-arm64::datashader==0.15.1=py311hca03da5_0\n",
      "  - defaults/osx-arm64::contourpy==1.0.5=py311h48ca7d4_0\n",
      "  - defaults/osx-arm64::scikit-learn==1.3.0=py311h7aedaa7_0\n",
      "  - defaults/osx-arm64::xarray==2023.6.0=py311hca03da5_0\n",
      "  - defaults/osx-arm64::pandas==2.0.3=py311h7aedaa7_0\n",
      "  - defaults/osx-arm64::scipy==1.10.1=py311hc76d9b0_1\n",
      "  - defaults/osx-arm64::hvplot==0.8.4=py311hca03da5_0\n",
      "  - defaults/osx-arm64::nltk==3.8.1=py311hca03da5_0\n",
      "  - defaults/osx-arm64::statsmodels==0.14.0=py311hb9f6ed7_0\n",
      "  - conda-forge/noarch::seaborn==0.12.2=hd8ed1ab_0\n",
      "  - defaults/osx-arm64::holoviews==1.17.0=py311hca03da5_0\n",
      "  - defaults/osx-arm64::imbalanced-learn==0.10.1=py311hca03da5_1\n",
      "  - defaults/osx-arm64::astropy==5.1=py311ha0d4635_0\n",
      "  - defaults/osx-arm64::_anaconda_depends==2023.07=py311_1\n",
      "  - defaults/osx-arm64::imageio==2.31.1=py311hca03da5_0\n",
      "  - defaults/osx-arm64::bottleneck==1.3.5=py311ha0d4635_0\n",
      "  - defaults/osx-arm64::gensim==4.3.0=py311h6956b77_0\n",
      "  - conda-forge/noarch::missingno==0.4.2=py_1\n",
      "  - defaults/osx-arm64::pytorch==2.0.1=gpu_mps_py311h0436fea_0\n",
      "  - defaults/osx-arm64::intake==0.6.8=py311hca03da5_0\n",
      "  - defaults/osx-arm64::h5py==3.7.0=py311h39e7838_0\n",
      "  - defaults/osx-arm64::arrow-cpp==11.0.0=py311h5aa4e29_0\n",
      "done\n",
      "\n",
      "## Package Plan ##\n",
      "\n",
      "  environment location: /Users/blandrumjeffries/anaconda3\n",
      "\n",
      "  added / updated specs:\n",
      "    - joblib\n",
      "    - numpy\n",
      "    - pandas\n",
      "    - pytorch\n",
      "    - scikit-learn\n",
      "    - scipy\n",
      "\n",
      "\n",
      "The following packages will be downloaded:\n",
      "\n",
      "    package                    |            build\n",
      "    ---------------------------|-----------------\n",
      "    ca-certificates-2023.08.22 |       hca03da5_0         124 KB\n",
      "    conda-23.7.4               |  py311hca03da5_0         1.3 MB\n",
      "    openssl-1.1.1w             |       h1a28f6b_0         3.1 MB\n",
      "    ------------------------------------------------------------\n",
      "                                           Total:         4.6 MB\n",
      "\n",
      "The following NEW packages will be INSTALLED:\n",
      "\n",
      "  joblib             pkgs/main/osx-arm64::joblib-1.2.0-py311hca03da5_0 \n",
      "  numpy-base         pkgs/main/osx-arm64::numpy-base-1.24.3-py311h1d85a46_0 \n",
      "\n",
      "The following packages will be UPDATED:\n",
      "\n",
      "  ca-certificates                     2023.05.30-hca03da5_0 --> 2023.08.22-hca03da5_0 \n",
      "  conda                              23.7.3-py311hca03da5_0 --> 23.7.4-py311hca03da5_0 \n",
      "  openssl                                 1.1.1v-h1a28f6b_0 --> 1.1.1w-h1a28f6b_0 \n",
      "\n",
      "\n",
      "\n",
      "Downloading and Extracting Packages\n",
      "ca-certificates-2023 | 124 KB    |                                       |   0% \n",
      "openssl-1.1.1w       | 3.1 MB    |                                       |   0% \u001b[A\n",
      "\n",
      "conda-23.7.4         | 1.3 MB    |                                       |   0% \u001b[A\u001b[ADEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): repo.anaconda.com:443\n",
      "DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): repo.anaconda.com:443\n",
      "DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): repo.anaconda.com:443\n",
      "DEBUG:urllib3.connectionpool:https://repo.anaconda.com:443 \"GET /pkgs/main/osx-arm64/openssl-1.1.1w-h1a28f6b_0.conda HTTP/1.1\" 200 3236436\n",
      "DEBUG:urllib3.connectionpool:https://repo.anaconda.com:443 \"GET /pkgs/main/osx-arm64/conda-23.7.4-py311hca03da5_0.conda HTTP/1.1\" 200 1408898\n",
      "\n",
      "\n",
      "conda-23.7.4         | 1.3 MB    | 8                                     |   2% \u001b[A\u001b[ADEBUG:urllib3.connectionpool:https://repo.anaconda.com:443 \"GET /pkgs/main/osx-arm64/ca-certificates-2023.08.22-hca03da5_0.conda HTTP/1.1\" 200 126588\n",
      "\n",
      "openssl-1.1.1w       | 3.1 MB    | #4                                    |   4% \u001b[A\n",
      "\n",
      "ca-certificates-2023 | 124 KB    | ##################################### | 100% \u001b[A\u001b[A\n",
      "openssl-1.1.1w       | 3.1 MB    | #########1                            |  25% \u001b[A\n",
      "\n",
      "conda-23.7.4         | 1.3 MB    | #################2                    |  47% \u001b[A\u001b[A\n",
      "openssl-1.1.1w       | 3.1 MB    | ##################1                   |  49% \u001b[A\n",
      "openssl-1.1.1w       | 3.1 MB    | ############################4         |  77% \u001b[A\n",
      "\n",
      "conda-23.7.4         | 1.3 MB    | ##################################### | 100% \u001b[A\u001b[A\n",
      "\n",
      "conda-23.7.4         | 1.3 MB    | ##################################### | 100% \u001b[A\u001b[A\n",
      "openssl-1.1.1w       | 3.1 MB    | ##################################### | 100% \u001b[A\n",
      "                                                                                \u001b[A\n",
      "                                                                                \u001b[A\n",
      "\n",
      "                                                                                \u001b[A\u001b[A\n",
      "Preparing transaction: done\n",
      "Verifying transaction: done\n",
      "Executing transaction: done\n",
      "\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "conda install numpy scipy scikit-learn pandas joblib pytorch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "11cb33a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting deap\n",
      "  Downloading deap-1.4.1.tar.gz (1.1 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting update_checker\n",
      "  Downloading update_checker-0.18.0-py3-none-any.whl (7.0 kB)\n",
      "Requirement already satisfied: tqdm in /Users/blandrumjeffries/anaconda3/lib/python3.11/site-packages (4.65.0)\n",
      "Collecting stopit\n",
      "  Downloading stopit-1.1.2.tar.gz (18 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting xgboost\n",
      "  Obtaining dependency information for xgboost from https://files.pythonhosted.org/packages/6d/d1/3e954de1d492129710e8625349a7b86eb287a4f413c5b5c15522f89a6c04/xgboost-2.0.0-py3-none-macosx_12_0_arm64.whl.metadata\n",
      "  Downloading xgboost-2.0.0-py3-none-macosx_12_0_arm64.whl.metadata (2.0 kB)\n",
      "Requirement already satisfied: numpy in /Users/blandrumjeffries/anaconda3/lib/python3.11/site-packages (from deap) (1.23.5)\n",
      "Requirement already satisfied: requests>=2.3.0 in /Users/blandrumjeffries/anaconda3/lib/python3.11/site-packages (from update_checker) (2.31.0)\n",
      "Requirement already satisfied: scipy in /Users/blandrumjeffries/anaconda3/lib/python3.11/site-packages (from xgboost) (1.10.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/blandrumjeffries/anaconda3/lib/python3.11/site-packages (from requests>=2.3.0->update_checker) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/blandrumjeffries/anaconda3/lib/python3.11/site-packages (from requests>=2.3.0->update_checker) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/blandrumjeffries/anaconda3/lib/python3.11/site-packages (from requests>=2.3.0->update_checker) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/blandrumjeffries/anaconda3/lib/python3.11/site-packages (from requests>=2.3.0->update_checker) (2023.7.22)\n",
      "Downloading xgboost-2.0.0-py3-none-macosx_12_0_arm64.whl (1.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hBuilding wheels for collected packages: deap, stopit\n",
      "  Building wheel for deap (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for deap: filename=deap-1.4.1-cp311-cp311-macosx_11_0_arm64.whl size=103881 sha256=1a4a106bc8e1f32d9819313571ba09af2cdc183596b40f6a6f0266ba03bf1cbb\n",
      "  Stored in directory: /Users/blandrumjeffries/Library/Caches/pip/wheels/f8/64/b8/65eacfbff3024ae2e2beb22e691d5c8abb89fbd863b8049b5f\n",
      "  Building wheel for stopit (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for stopit: filename=stopit-1.1.2-py3-none-any.whl size=11937 sha256=381c0d2a75a5d78da153037ef435c98bfac1a54bab232d0001a7f4c96b0071eb\n",
      "  Stored in directory: /Users/blandrumjeffries/Library/Caches/pip/wheels/da/77/2d/adbc56bc4db95ad80c6d4e71cd69e2d9d122174904342e3f7f\n",
      "Successfully built deap stopit\n",
      "Installing collected packages: stopit, deap, xgboost, update_checker\n",
      "Successfully installed deap-1.4.1 stopit-1.1.2 update_checker-0.18.0 xgboost-2.0.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install deap update_checker tqdm stopit xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fd39571b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tpot\n",
      "  Obtaining dependency information for tpot from https://files.pythonhosted.org/packages/7b/a7/0060d028906ecd058b1331c3ce6f3f19ba03464b21dc9abbbaf66b0a1091/TPOT-0.12.1-py3-none-any.whl.metadata\n",
      "  Downloading TPOT-0.12.1-py3-none-any.whl.metadata (2.0 kB)\n",
      "Requirement already satisfied: numpy>=1.16.3 in /Users/blandrumjeffries/anaconda3/lib/python3.11/site-packages (from tpot) (1.23.5)\n",
      "Requirement already satisfied: scipy>=1.3.1 in /Users/blandrumjeffries/anaconda3/lib/python3.11/site-packages (from tpot) (1.10.1)\n",
      "Requirement already satisfied: scikit-learn>=0.22.0 in /Users/blandrumjeffries/anaconda3/lib/python3.11/site-packages (from tpot) (1.3.0)\n",
      "Requirement already satisfied: deap>=1.2 in /Users/blandrumjeffries/anaconda3/lib/python3.11/site-packages (from tpot) (1.4.1)\n",
      "Requirement already satisfied: update-checker>=0.16 in /Users/blandrumjeffries/anaconda3/lib/python3.11/site-packages (from tpot) (0.18.0)\n",
      "Requirement already satisfied: tqdm>=4.36.1 in /Users/blandrumjeffries/anaconda3/lib/python3.11/site-packages (from tpot) (4.65.0)\n",
      "Requirement already satisfied: stopit>=1.1.1 in /Users/blandrumjeffries/anaconda3/lib/python3.11/site-packages (from tpot) (1.1.2)\n",
      "Requirement already satisfied: pandas>=0.24.2 in /Users/blandrumjeffries/anaconda3/lib/python3.11/site-packages (from tpot) (2.0.3)\n",
      "Requirement already satisfied: joblib>=0.13.2 in /Users/blandrumjeffries/anaconda3/lib/python3.11/site-packages (from tpot) (1.2.0)\n",
      "Requirement already satisfied: xgboost>=1.1.0 in /Users/blandrumjeffries/anaconda3/lib/python3.11/site-packages (from tpot) (2.0.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/blandrumjeffries/anaconda3/lib/python3.11/site-packages (from pandas>=0.24.2->tpot) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/blandrumjeffries/anaconda3/lib/python3.11/site-packages (from pandas>=0.24.2->tpot) (2022.7)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /Users/blandrumjeffries/anaconda3/lib/python3.11/site-packages (from pandas>=0.24.2->tpot) (2023.3)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /Users/blandrumjeffries/anaconda3/lib/python3.11/site-packages (from scikit-learn>=0.22.0->tpot) (2.2.0)\n",
      "Requirement already satisfied: requests>=2.3.0 in /Users/blandrumjeffries/anaconda3/lib/python3.11/site-packages (from update-checker>=0.16->tpot) (2.31.0)\n",
      "Requirement already satisfied: six>=1.5 in /Users/blandrumjeffries/anaconda3/lib/python3.11/site-packages (from python-dateutil>=2.8.2->pandas>=0.24.2->tpot) (1.16.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/blandrumjeffries/anaconda3/lib/python3.11/site-packages (from requests>=2.3.0->update-checker>=0.16->tpot) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/blandrumjeffries/anaconda3/lib/python3.11/site-packages (from requests>=2.3.0->update-checker>=0.16->tpot) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/blandrumjeffries/anaconda3/lib/python3.11/site-packages (from requests>=2.3.0->update-checker>=0.16->tpot) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/blandrumjeffries/anaconda3/lib/python3.11/site-packages (from requests>=2.3.0->update-checker>=0.16->tpot) (2023.7.22)\n",
      "Downloading TPOT-0.12.1-py3-none-any.whl (87 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m87.4/87.4 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: tpot\n",
      "Successfully installed tpot-0.12.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install tpot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e4b3dd2b",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tpot in /Users/blandrumjeffries/anaconda3/lib/python3.11/site-packages (0.12.1)\n",
      "Requirement already satisfied: numpy>=1.16.3 in /Users/blandrumjeffries/anaconda3/lib/python3.11/site-packages (from tpot) (1.23.5)\n",
      "Requirement already satisfied: scipy>=1.3.1 in /Users/blandrumjeffries/anaconda3/lib/python3.11/site-packages (from tpot) (1.10.1)\n",
      "Requirement already satisfied: scikit-learn>=0.22.0 in /Users/blandrumjeffries/anaconda3/lib/python3.11/site-packages (from tpot) (1.3.0)\n",
      "Requirement already satisfied: deap>=1.2 in /Users/blandrumjeffries/anaconda3/lib/python3.11/site-packages (from tpot) (1.4.1)\n",
      "Requirement already satisfied: update-checker>=0.16 in /Users/blandrumjeffries/anaconda3/lib/python3.11/site-packages (from tpot) (0.18.0)\n",
      "Requirement already satisfied: tqdm>=4.36.1 in /Users/blandrumjeffries/anaconda3/lib/python3.11/site-packages (from tpot) (4.65.0)\n",
      "Requirement already satisfied: stopit>=1.1.1 in /Users/blandrumjeffries/anaconda3/lib/python3.11/site-packages (from tpot) (1.1.2)\n",
      "Requirement already satisfied: pandas>=0.24.2 in /Users/blandrumjeffries/anaconda3/lib/python3.11/site-packages (from tpot) (2.0.3)\n",
      "Requirement already satisfied: joblib>=0.13.2 in /Users/blandrumjeffries/anaconda3/lib/python3.11/site-packages (from tpot) (1.2.0)\n",
      "Requirement already satisfied: xgboost>=1.1.0 in /Users/blandrumjeffries/anaconda3/lib/python3.11/site-packages (from tpot) (2.0.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/blandrumjeffries/anaconda3/lib/python3.11/site-packages (from pandas>=0.24.2->tpot) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/blandrumjeffries/anaconda3/lib/python3.11/site-packages (from pandas>=0.24.2->tpot) (2022.7)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /Users/blandrumjeffries/anaconda3/lib/python3.11/site-packages (from pandas>=0.24.2->tpot) (2023.3)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /Users/blandrumjeffries/anaconda3/lib/python3.11/site-packages (from scikit-learn>=0.22.0->tpot) (2.2.0)\n",
      "Requirement already satisfied: requests>=2.3.0 in /Users/blandrumjeffries/anaconda3/lib/python3.11/site-packages (from update-checker>=0.16->tpot) (2.31.0)\n",
      "Requirement already satisfied: six>=1.5 in /Users/blandrumjeffries/anaconda3/lib/python3.11/site-packages (from python-dateutil>=2.8.2->pandas>=0.24.2->tpot) (1.16.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/blandrumjeffries/anaconda3/lib/python3.11/site-packages (from requests>=2.3.0->update-checker>=0.16->tpot) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/blandrumjeffries/anaconda3/lib/python3.11/site-packages (from requests>=2.3.0->update-checker>=0.16->tpot) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/blandrumjeffries/anaconda3/lib/python3.11/site-packages (from requests>=2.3.0->update-checker>=0.16->tpot) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/blandrumjeffries/anaconda3/lib/python3.11/site-packages (from requests>=2.3.0->update-checker>=0.16->tpot) (2023.7.22)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install tpot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c744b1c0",
   "metadata": {},
   "source": [
    "## Small Note\n",
    "\n",
    "Above I installed the required modules to run the code. It was nice because I did not need to fix any errors or deprecations. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c426b3ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "\n",
    "from tpot import TPOTClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import timeit "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2f63202d",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>customerID</th>\n",
       "      <th>tenure</th>\n",
       "      <th>PhoneService</th>\n",
       "      <th>Contract</th>\n",
       "      <th>PaymentMethod</th>\n",
       "      <th>MonthlyCharges</th>\n",
       "      <th>TotalCharges</th>\n",
       "      <th>Churn</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7590-VHVEG</td>\n",
       "      <td>1</td>\n",
       "      <td>No</td>\n",
       "      <td>Month-to-month</td>\n",
       "      <td>Electronic check</td>\n",
       "      <td>29.85</td>\n",
       "      <td>29.85</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5575-GNVDE</td>\n",
       "      <td>34</td>\n",
       "      <td>Yes</td>\n",
       "      <td>One year</td>\n",
       "      <td>Mailed check</td>\n",
       "      <td>56.95</td>\n",
       "      <td>1889.50</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3668-QPYBK</td>\n",
       "      <td>2</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Month-to-month</td>\n",
       "      <td>Mailed check</td>\n",
       "      <td>53.85</td>\n",
       "      <td>108.15</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7795-CFOCW</td>\n",
       "      <td>45</td>\n",
       "      <td>No</td>\n",
       "      <td>One year</td>\n",
       "      <td>Bank transfer (automatic)</td>\n",
       "      <td>42.30</td>\n",
       "      <td>1840.75</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9237-HQITU</td>\n",
       "      <td>2</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Month-to-month</td>\n",
       "      <td>Electronic check</td>\n",
       "      <td>70.70</td>\n",
       "      <td>151.65</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   customerID  tenure PhoneService        Contract              PaymentMethod  \\\n",
       "0  7590-VHVEG       1           No  Month-to-month           Electronic check   \n",
       "1  5575-GNVDE      34          Yes        One year               Mailed check   \n",
       "2  3668-QPYBK       2          Yes  Month-to-month               Mailed check   \n",
       "3  7795-CFOCW      45           No        One year  Bank transfer (automatic)   \n",
       "4  9237-HQITU       2          Yes  Month-to-month           Electronic check   \n",
       "\n",
       "   MonthlyCharges  TotalCharges Churn  \n",
       "0           29.85         29.85    No  \n",
       "1           56.95       1889.50    No  \n",
       "2           53.85        108.15   Yes  \n",
       "3           42.30       1840.75    No  \n",
       "4           70.70        151.65   Yes  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('/Users/blandrumjeffries/Downloads/churn_data.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "45c6e37c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Churn'] = df['Churn'].replace({'No': 0, 'Yes': 1})\n",
    "df['Churn']\n",
    "\n",
    "df['Contract'] = df['Contract'].replace({'Month-to-month': 0, 'One year': 1, 'Two year': 2})\n",
    "\n",
    "df['PaymentMethod'] = df['PaymentMethod'].replace({'Electronic check': 0, 'Mailed check': 1, 'Credit card (automatic)': 2, 'Bank transfer (automatic)': 3})\n",
    "\n",
    "df['PhoneService'] = df['PhoneService'].replace({'No': 0, 'Yes': 1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "cdcfa754",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop('customerID', axis=1, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "19f15914",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('WEEK5FIXEDDATA.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ee9bee1",
   "metadata": {},
   "source": [
    "## Small note\n",
    "Again this recurring issue, I took the right file that was editied and it complains about the axis always. But I saved the data so no big deal!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "56788ba4",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = df.drop('Churn', axis=1)\n",
    "targets = df['Churn']\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(features, targets, stratify=targets, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "394737e4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 7043 entries, 0 to 7042\n",
      "Data columns (total 8 columns):\n",
      " #   Column          Non-Null Count  Dtype  \n",
      "---  ------          --------------  -----  \n",
      " 0   customerID      7043 non-null   object \n",
      " 1   tenure          7043 non-null   int64  \n",
      " 2   PhoneService    7043 non-null   int64  \n",
      " 3   Contract        7043 non-null   int64  \n",
      " 4   PaymentMethod   7043 non-null   int64  \n",
      " 5   MonthlyCharges  7043 non-null   float64\n",
      " 6   TotalCharges    7032 non-null   float64\n",
      " 7   Churn           7043 non-null   int64  \n",
      "dtypes: float64(2), int64(5), object(1)\n",
      "memory usage: 440.3+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4f755af3",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = df.drop('Churn', axis=1)\n",
    "targets = df['Churn']\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(features, targets, stratify=targets, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e7bca7b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imputing missing values in feature set\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Optimization Progress:   0%|          | 0/300 [00:00<?, ?pipeline/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Generation 1 - Current best internal CV score: 0.7654634630905817\n",
      "\n",
      "Generation 2 - Current best internal CV score: 0.7654634630905817\n",
      "\n",
      "Generation 3 - Current best internal CV score: 0.7654634630905817\n",
      "\n",
      "Generation 4 - Current best internal CV score: 0.7874905211747317\n",
      "\n",
      "Generation 5 - Current best internal CV score: 0.7948519948519949\n",
      "\n",
      "Best pipeline: XGBClassifier(Nystroem(input_matrix, gamma=0.7000000000000001, kernel=additive_chi2, n_components=1), learning_rate=0.01, max_depth=6, min_child_weight=16, n_estimators=100, n_jobs=1, subsample=0.8500000000000001, verbosity=0)\n",
      "Imputing missing values in feature set\n",
      "0.7894736842105263\n",
      "CPU times: user 23.3 s, sys: 9.64 s, total: 33 s\n",
      "Wall time: 55.8 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "tpot = TPOTClassifier(generations=5, population_size=50, cv=5,random_state=42, scoring='precision', verbosity=2, n_jobs=-1)\n",
    "\n",
    "tpot.fit(x_train, y_train)\n",
    "print(tpot.score(x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7d6a94ed",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imputing missing values in feature set\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, ..., 0, 0, 0])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = tpot.predict(x_test)\n",
    "predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cf275c4",
   "metadata": {},
   "source": [
    "I used precision because I feel like it fit better than the accruacy. Then the predicition per row."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d02fa745",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions for test data set\n",
      "[0 0 0 ... 0 0 0]\n",
      "Actuals for test data set\n",
      "5909    0\n",
      "3670    0\n",
      "6220    0\n",
      "5905    0\n",
      "6435    0\n",
      "       ..\n",
      "476     0\n",
      "1607    1\n",
      "6808    0\n",
      "2962    1\n",
      "3955    0\n",
      "Name: Churn, Length: 1761, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print('Predictions for test data set')\n",
    "print(predictions)\n",
    "print('Actuals for test data set')\n",
    "print(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6ab25932",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the TPOT predictions: 0.7535491198182851\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "print(f'Accuracy of the TPOT predictions: {accuracy_score(y_test,predictions)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "cb111331",
   "metadata": {},
   "outputs": [],
   "source": [
    "tpot.export('tpot_churn_pipeline.py')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "53d5eb2b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>pre { line-height: 125%; }\n",
       "td.linenos .normal { color: inherit; background-color: transparent; padding-left: 5px; padding-right: 5px; }\n",
       "span.linenos { color: inherit; background-color: transparent; padding-left: 5px; padding-right: 5px; }\n",
       "td.linenos .special { color: #000000; background-color: #ffffc0; padding-left: 5px; padding-right: 5px; }\n",
       "span.linenos.special { color: #000000; background-color: #ffffc0; padding-left: 5px; padding-right: 5px; }\n",
       ".output_html .hll { background-color: #ffffcc }\n",
       ".output_html { background: #f8f8f8; }\n",
       ".output_html .c { color: #3D7B7B; font-style: italic } /* Comment */\n",
       ".output_html .err { border: 1px solid #FF0000 } /* Error */\n",
       ".output_html .k { color: #008000; font-weight: bold } /* Keyword */\n",
       ".output_html .o { color: #666666 } /* Operator */\n",
       ".output_html .ch { color: #3D7B7B; font-style: italic } /* Comment.Hashbang */\n",
       ".output_html .cm { color: #3D7B7B; font-style: italic } /* Comment.Multiline */\n",
       ".output_html .cp { color: #9C6500 } /* Comment.Preproc */\n",
       ".output_html .cpf { color: #3D7B7B; font-style: italic } /* Comment.PreprocFile */\n",
       ".output_html .c1 { color: #3D7B7B; font-style: italic } /* Comment.Single */\n",
       ".output_html .cs { color: #3D7B7B; font-style: italic } /* Comment.Special */\n",
       ".output_html .gd { color: #A00000 } /* Generic.Deleted */\n",
       ".output_html .ge { font-style: italic } /* Generic.Emph */\n",
       ".output_html .gr { color: #E40000 } /* Generic.Error */\n",
       ".output_html .gh { color: #000080; font-weight: bold } /* Generic.Heading */\n",
       ".output_html .gi { color: #008400 } /* Generic.Inserted */\n",
       ".output_html .go { color: #717171 } /* Generic.Output */\n",
       ".output_html .gp { color: #000080; font-weight: bold } /* Generic.Prompt */\n",
       ".output_html .gs { font-weight: bold } /* Generic.Strong */\n",
       ".output_html .gu { color: #800080; font-weight: bold } /* Generic.Subheading */\n",
       ".output_html .gt { color: #0044DD } /* Generic.Traceback */\n",
       ".output_html .kc { color: #008000; font-weight: bold } /* Keyword.Constant */\n",
       ".output_html .kd { color: #008000; font-weight: bold } /* Keyword.Declaration */\n",
       ".output_html .kn { color: #008000; font-weight: bold } /* Keyword.Namespace */\n",
       ".output_html .kp { color: #008000 } /* Keyword.Pseudo */\n",
       ".output_html .kr { color: #008000; font-weight: bold } /* Keyword.Reserved */\n",
       ".output_html .kt { color: #B00040 } /* Keyword.Type */\n",
       ".output_html .m { color: #666666 } /* Literal.Number */\n",
       ".output_html .s { color: #BA2121 } /* Literal.String */\n",
       ".output_html .na { color: #687822 } /* Name.Attribute */\n",
       ".output_html .nb { color: #008000 } /* Name.Builtin */\n",
       ".output_html .nc { color: #0000FF; font-weight: bold } /* Name.Class */\n",
       ".output_html .no { color: #880000 } /* Name.Constant */\n",
       ".output_html .nd { color: #AA22FF } /* Name.Decorator */\n",
       ".output_html .ni { color: #717171; font-weight: bold } /* Name.Entity */\n",
       ".output_html .ne { color: #CB3F38; font-weight: bold } /* Name.Exception */\n",
       ".output_html .nf { color: #0000FF } /* Name.Function */\n",
       ".output_html .nl { color: #767600 } /* Name.Label */\n",
       ".output_html .nn { color: #0000FF; font-weight: bold } /* Name.Namespace */\n",
       ".output_html .nt { color: #008000; font-weight: bold } /* Name.Tag */\n",
       ".output_html .nv { color: #19177C } /* Name.Variable */\n",
       ".output_html .ow { color: #AA22FF; font-weight: bold } /* Operator.Word */\n",
       ".output_html .w { color: #bbbbbb } /* Text.Whitespace */\n",
       ".output_html .mb { color: #666666 } /* Literal.Number.Bin */\n",
       ".output_html .mf { color: #666666 } /* Literal.Number.Float */\n",
       ".output_html .mh { color: #666666 } /* Literal.Number.Hex */\n",
       ".output_html .mi { color: #666666 } /* Literal.Number.Integer */\n",
       ".output_html .mo { color: #666666 } /* Literal.Number.Oct */\n",
       ".output_html .sa { color: #BA2121 } /* Literal.String.Affix */\n",
       ".output_html .sb { color: #BA2121 } /* Literal.String.Backtick */\n",
       ".output_html .sc { color: #BA2121 } /* Literal.String.Char */\n",
       ".output_html .dl { color: #BA2121 } /* Literal.String.Delimiter */\n",
       ".output_html .sd { color: #BA2121; font-style: italic } /* Literal.String.Doc */\n",
       ".output_html .s2 { color: #BA2121 } /* Literal.String.Double */\n",
       ".output_html .se { color: #AA5D1F; font-weight: bold } /* Literal.String.Escape */\n",
       ".output_html .sh { color: #BA2121 } /* Literal.String.Heredoc */\n",
       ".output_html .si { color: #A45A77; font-weight: bold } /* Literal.String.Interpol */\n",
       ".output_html .sx { color: #008000 } /* Literal.String.Other */\n",
       ".output_html .sr { color: #A45A77 } /* Literal.String.Regex */\n",
       ".output_html .s1 { color: #BA2121 } /* Literal.String.Single */\n",
       ".output_html .ss { color: #19177C } /* Literal.String.Symbol */\n",
       ".output_html .bp { color: #008000 } /* Name.Builtin.Pseudo */\n",
       ".output_html .fm { color: #0000FF } /* Name.Function.Magic */\n",
       ".output_html .vc { color: #19177C } /* Name.Variable.Class */\n",
       ".output_html .vg { color: #19177C } /* Name.Variable.Global */\n",
       ".output_html .vi { color: #19177C } /* Name.Variable.Instance */\n",
       ".output_html .vm { color: #19177C } /* Name.Variable.Magic */\n",
       ".output_html .il { color: #666666 } /* Literal.Number.Integer.Long */</style><div class=\"highlight\"><pre><span></span><span class=\"kn\">import</span> <span class=\"nn\">numpy</span> <span class=\"k\">as</span> <span class=\"nn\">np</span>\n",
       "<span class=\"kn\">import</span> <span class=\"nn\">pandas</span> <span class=\"k\">as</span> <span class=\"nn\">pd</span>\n",
       "<span class=\"kn\">from</span> <span class=\"nn\">sklearn.kernel_approximation</span> <span class=\"kn\">import</span> <span class=\"n\">Nystroem</span>\n",
       "<span class=\"kn\">from</span> <span class=\"nn\">sklearn.model_selection</span> <span class=\"kn\">import</span> <span class=\"n\">train_test_split</span>\n",
       "<span class=\"kn\">from</span> <span class=\"nn\">sklearn.pipeline</span> <span class=\"kn\">import</span> <span class=\"n\">make_pipeline</span>\n",
       "<span class=\"kn\">from</span> <span class=\"nn\">xgboost</span> <span class=\"kn\">import</span> <span class=\"n\">XGBClassifier</span>\n",
       "<span class=\"kn\">from</span> <span class=\"nn\">sklearn.impute</span> <span class=\"kn\">import</span> <span class=\"n\">SimpleImputer</span>\n",
       "<span class=\"kn\">from</span> <span class=\"nn\">tpot.export_utils</span> <span class=\"kn\">import</span> <span class=\"n\">set_param_recursive</span>\n",
       "\n",
       "<span class=\"c1\"># NOTE: Make sure that the outcome column is labeled &#39;target&#39; in the data file</span>\n",
       "<span class=\"n\">tpot_data</span> <span class=\"o\">=</span> <span class=\"n\">pd</span><span class=\"o\">.</span><span class=\"n\">read_csv</span><span class=\"p\">(</span><span class=\"s1\">&#39;PATH/TO/DATA/FILE&#39;</span><span class=\"p\">,</span> <span class=\"n\">sep</span><span class=\"o\">=</span><span class=\"s1\">&#39;COLUMN_SEPARATOR&#39;</span><span class=\"p\">,</span> <span class=\"n\">dtype</span><span class=\"o\">=</span><span class=\"n\">np</span><span class=\"o\">.</span><span class=\"n\">float64</span><span class=\"p\">)</span>\n",
       "<span class=\"n\">features</span> <span class=\"o\">=</span> <span class=\"n\">tpot_data</span><span class=\"o\">.</span><span class=\"n\">drop</span><span class=\"p\">(</span><span class=\"s1\">&#39;target&#39;</span><span class=\"p\">,</span> <span class=\"n\">axis</span><span class=\"o\">=</span><span class=\"mi\">1</span><span class=\"p\">)</span>\n",
       "<span class=\"n\">training_features</span><span class=\"p\">,</span> <span class=\"n\">testing_features</span><span class=\"p\">,</span> <span class=\"n\">training_target</span><span class=\"p\">,</span> <span class=\"n\">testing_target</span> <span class=\"o\">=</span> \\\n",
       "            <span class=\"n\">train_test_split</span><span class=\"p\">(</span><span class=\"n\">features</span><span class=\"p\">,</span> <span class=\"n\">tpot_data</span><span class=\"p\">[</span><span class=\"s1\">&#39;target&#39;</span><span class=\"p\">],</span> <span class=\"n\">random_state</span><span class=\"o\">=</span><span class=\"mi\">42</span><span class=\"p\">)</span>\n",
       "\n",
       "<span class=\"n\">imputer</span> <span class=\"o\">=</span> <span class=\"n\">SimpleImputer</span><span class=\"p\">(</span><span class=\"n\">strategy</span><span class=\"o\">=</span><span class=\"s2\">&quot;median&quot;</span><span class=\"p\">)</span>\n",
       "<span class=\"n\">imputer</span><span class=\"o\">.</span><span class=\"n\">fit</span><span class=\"p\">(</span><span class=\"n\">training_features</span><span class=\"p\">)</span>\n",
       "<span class=\"n\">training_features</span> <span class=\"o\">=</span> <span class=\"n\">imputer</span><span class=\"o\">.</span><span class=\"n\">transform</span><span class=\"p\">(</span><span class=\"n\">training_features</span><span class=\"p\">)</span>\n",
       "<span class=\"n\">testing_features</span> <span class=\"o\">=</span> <span class=\"n\">imputer</span><span class=\"o\">.</span><span class=\"n\">transform</span><span class=\"p\">(</span><span class=\"n\">testing_features</span><span class=\"p\">)</span>\n",
       "\n",
       "<span class=\"c1\"># Average CV score on the training set was: 0.7948519948519949</span>\n",
       "<span class=\"n\">exported_pipeline</span> <span class=\"o\">=</span> <span class=\"n\">make_pipeline</span><span class=\"p\">(</span>\n",
       "    <span class=\"n\">Nystroem</span><span class=\"p\">(</span><span class=\"n\">gamma</span><span class=\"o\">=</span><span class=\"mf\">0.7000000000000001</span><span class=\"p\">,</span> <span class=\"n\">kernel</span><span class=\"o\">=</span><span class=\"s2\">&quot;additive_chi2&quot;</span><span class=\"p\">,</span> <span class=\"n\">n_components</span><span class=\"o\">=</span><span class=\"mi\">1</span><span class=\"p\">),</span>\n",
       "    <span class=\"n\">XGBClassifier</span><span class=\"p\">(</span><span class=\"n\">learning_rate</span><span class=\"o\">=</span><span class=\"mf\">0.01</span><span class=\"p\">,</span> <span class=\"n\">max_depth</span><span class=\"o\">=</span><span class=\"mi\">6</span><span class=\"p\">,</span> <span class=\"n\">min_child_weight</span><span class=\"o\">=</span><span class=\"mi\">16</span><span class=\"p\">,</span> <span class=\"n\">n_estimators</span><span class=\"o\">=</span><span class=\"mi\">100</span><span class=\"p\">,</span> <span class=\"n\">n_jobs</span><span class=\"o\">=</span><span class=\"mi\">1</span><span class=\"p\">,</span> <span class=\"n\">subsample</span><span class=\"o\">=</span><span class=\"mf\">0.8500000000000001</span><span class=\"p\">,</span> <span class=\"n\">verbosity</span><span class=\"o\">=</span><span class=\"mi\">0</span><span class=\"p\">)</span>\n",
       "<span class=\"p\">)</span>\n",
       "<span class=\"c1\"># Fix random state for all the steps in exported pipeline</span>\n",
       "<span class=\"n\">set_param_recursive</span><span class=\"p\">(</span><span class=\"n\">exported_pipeline</span><span class=\"o\">.</span><span class=\"n\">steps</span><span class=\"p\">,</span> <span class=\"s1\">&#39;random_state&#39;</span><span class=\"p\">,</span> <span class=\"mi\">42</span><span class=\"p\">)</span>\n",
       "\n",
       "<span class=\"n\">exported_pipeline</span><span class=\"o\">.</span><span class=\"n\">fit</span><span class=\"p\">(</span><span class=\"n\">training_features</span><span class=\"p\">,</span> <span class=\"n\">training_target</span><span class=\"p\">)</span>\n",
       "<span class=\"n\">results</span> <span class=\"o\">=</span> <span class=\"n\">exported_pipeline</span><span class=\"o\">.</span><span class=\"n\">predict</span><span class=\"p\">(</span><span class=\"n\">testing_features</span><span class=\"p\">)</span>\n",
       "</pre></div>\n"
      ],
      "text/latex": [
       "\\begin{Verbatim}[commandchars=\\\\\\{\\}]\n",
       "\\PY{k+kn}{import} \\PY{n+nn}{numpy} \\PY{k}{as} \\PY{n+nn}{np}\n",
       "\\PY{k+kn}{import} \\PY{n+nn}{pandas} \\PY{k}{as} \\PY{n+nn}{pd}\n",
       "\\PY{k+kn}{from} \\PY{n+nn}{sklearn}\\PY{n+nn}{.}\\PY{n+nn}{kernel\\PYZus{}approximation} \\PY{k+kn}{import} \\PY{n}{Nystroem}\n",
       "\\PY{k+kn}{from} \\PY{n+nn}{sklearn}\\PY{n+nn}{.}\\PY{n+nn}{model\\PYZus{}selection} \\PY{k+kn}{import} \\PY{n}{train\\PYZus{}test\\PYZus{}split}\n",
       "\\PY{k+kn}{from} \\PY{n+nn}{sklearn}\\PY{n+nn}{.}\\PY{n+nn}{pipeline} \\PY{k+kn}{import} \\PY{n}{make\\PYZus{}pipeline}\n",
       "\\PY{k+kn}{from} \\PY{n+nn}{xgboost} \\PY{k+kn}{import} \\PY{n}{XGBClassifier}\n",
       "\\PY{k+kn}{from} \\PY{n+nn}{sklearn}\\PY{n+nn}{.}\\PY{n+nn}{impute} \\PY{k+kn}{import} \\PY{n}{SimpleImputer}\n",
       "\\PY{k+kn}{from} \\PY{n+nn}{tpot}\\PY{n+nn}{.}\\PY{n+nn}{export\\PYZus{}utils} \\PY{k+kn}{import} \\PY{n}{set\\PYZus{}param\\PYZus{}recursive}\n",
       "\n",
       "\\PY{c+c1}{\\PYZsh{} NOTE: Make sure that the outcome column is labeled \\PYZsq{}target\\PYZsq{} in the data file}\n",
       "\\PY{n}{tpot\\PYZus{}data} \\PY{o}{=} \\PY{n}{pd}\\PY{o}{.}\\PY{n}{read\\PYZus{}csv}\\PY{p}{(}\\PY{l+s+s1}{\\PYZsq{}}\\PY{l+s+s1}{PATH/TO/DATA/FILE}\\PY{l+s+s1}{\\PYZsq{}}\\PY{p}{,} \\PY{n}{sep}\\PY{o}{=}\\PY{l+s+s1}{\\PYZsq{}}\\PY{l+s+s1}{COLUMN\\PYZus{}SEPARATOR}\\PY{l+s+s1}{\\PYZsq{}}\\PY{p}{,} \\PY{n}{dtype}\\PY{o}{=}\\PY{n}{np}\\PY{o}{.}\\PY{n}{float64}\\PY{p}{)}\n",
       "\\PY{n}{features} \\PY{o}{=} \\PY{n}{tpot\\PYZus{}data}\\PY{o}{.}\\PY{n}{drop}\\PY{p}{(}\\PY{l+s+s1}{\\PYZsq{}}\\PY{l+s+s1}{target}\\PY{l+s+s1}{\\PYZsq{}}\\PY{p}{,} \\PY{n}{axis}\\PY{o}{=}\\PY{l+m+mi}{1}\\PY{p}{)}\n",
       "\\PY{n}{training\\PYZus{}features}\\PY{p}{,} \\PY{n}{testing\\PYZus{}features}\\PY{p}{,} \\PY{n}{training\\PYZus{}target}\\PY{p}{,} \\PY{n}{testing\\PYZus{}target} \\PY{o}{=} \\PYZbs{}\n",
       "            \\PY{n}{train\\PYZus{}test\\PYZus{}split}\\PY{p}{(}\\PY{n}{features}\\PY{p}{,} \\PY{n}{tpot\\PYZus{}data}\\PY{p}{[}\\PY{l+s+s1}{\\PYZsq{}}\\PY{l+s+s1}{target}\\PY{l+s+s1}{\\PYZsq{}}\\PY{p}{]}\\PY{p}{,} \\PY{n}{random\\PYZus{}state}\\PY{o}{=}\\PY{l+m+mi}{42}\\PY{p}{)}\n",
       "\n",
       "\\PY{n}{imputer} \\PY{o}{=} \\PY{n}{SimpleImputer}\\PY{p}{(}\\PY{n}{strategy}\\PY{o}{=}\\PY{l+s+s2}{\\PYZdq{}}\\PY{l+s+s2}{median}\\PY{l+s+s2}{\\PYZdq{}}\\PY{p}{)}\n",
       "\\PY{n}{imputer}\\PY{o}{.}\\PY{n}{fit}\\PY{p}{(}\\PY{n}{training\\PYZus{}features}\\PY{p}{)}\n",
       "\\PY{n}{training\\PYZus{}features} \\PY{o}{=} \\PY{n}{imputer}\\PY{o}{.}\\PY{n}{transform}\\PY{p}{(}\\PY{n}{training\\PYZus{}features}\\PY{p}{)}\n",
       "\\PY{n}{testing\\PYZus{}features} \\PY{o}{=} \\PY{n}{imputer}\\PY{o}{.}\\PY{n}{transform}\\PY{p}{(}\\PY{n}{testing\\PYZus{}features}\\PY{p}{)}\n",
       "\n",
       "\\PY{c+c1}{\\PYZsh{} Average CV score on the training set was: 0.7948519948519949}\n",
       "\\PY{n}{exported\\PYZus{}pipeline} \\PY{o}{=} \\PY{n}{make\\PYZus{}pipeline}\\PY{p}{(}\n",
       "    \\PY{n}{Nystroem}\\PY{p}{(}\\PY{n}{gamma}\\PY{o}{=}\\PY{l+m+mf}{0.7000000000000001}\\PY{p}{,} \\PY{n}{kernel}\\PY{o}{=}\\PY{l+s+s2}{\\PYZdq{}}\\PY{l+s+s2}{additive\\PYZus{}chi2}\\PY{l+s+s2}{\\PYZdq{}}\\PY{p}{,} \\PY{n}{n\\PYZus{}components}\\PY{o}{=}\\PY{l+m+mi}{1}\\PY{p}{)}\\PY{p}{,}\n",
       "    \\PY{n}{XGBClassifier}\\PY{p}{(}\\PY{n}{learning\\PYZus{}rate}\\PY{o}{=}\\PY{l+m+mf}{0.01}\\PY{p}{,} \\PY{n}{max\\PYZus{}depth}\\PY{o}{=}\\PY{l+m+mi}{6}\\PY{p}{,} \\PY{n}{min\\PYZus{}child\\PYZus{}weight}\\PY{o}{=}\\PY{l+m+mi}{16}\\PY{p}{,} \\PY{n}{n\\PYZus{}estimators}\\PY{o}{=}\\PY{l+m+mi}{100}\\PY{p}{,} \\PY{n}{n\\PYZus{}jobs}\\PY{o}{=}\\PY{l+m+mi}{1}\\PY{p}{,} \\PY{n}{subsample}\\PY{o}{=}\\PY{l+m+mf}{0.8500000000000001}\\PY{p}{,} \\PY{n}{verbosity}\\PY{o}{=}\\PY{l+m+mi}{0}\\PY{p}{)}\n",
       "\\PY{p}{)}\n",
       "\\PY{c+c1}{\\PYZsh{} Fix random state for all the steps in exported pipeline}\n",
       "\\PY{n}{set\\PYZus{}param\\PYZus{}recursive}\\PY{p}{(}\\PY{n}{exported\\PYZus{}pipeline}\\PY{o}{.}\\PY{n}{steps}\\PY{p}{,} \\PY{l+s+s1}{\\PYZsq{}}\\PY{l+s+s1}{random\\PYZus{}state}\\PY{l+s+s1}{\\PYZsq{}}\\PY{p}{,} \\PY{l+m+mi}{42}\\PY{p}{)}\n",
       "\n",
       "\\PY{n}{exported\\PYZus{}pipeline}\\PY{o}{.}\\PY{n}{fit}\\PY{p}{(}\\PY{n}{training\\PYZus{}features}\\PY{p}{,} \\PY{n}{training\\PYZus{}target}\\PY{p}{)}\n",
       "\\PY{n}{results} \\PY{o}{=} \\PY{n}{exported\\PYZus{}pipeline}\\PY{o}{.}\\PY{n}{predict}\\PY{p}{(}\\PY{n}{testing\\PYZus{}features}\\PY{p}{)}\n",
       "\\end{Verbatim}\n"
      ],
      "text/plain": [
       "import numpy as np\n",
       "import pandas as pd\n",
       "from sklearn.kernel_approximation import Nystroem\n",
       "from sklearn.model_selection import train_test_split\n",
       "from sklearn.pipeline import make_pipeline\n",
       "from xgboost import XGBClassifier\n",
       "from sklearn.impute import SimpleImputer\n",
       "from tpot.export_utils import set_param_recursive\n",
       "\n",
       "# NOTE: Make sure that the outcome column is labeled 'target' in the data file\n",
       "tpot_data = pd.read_csv('PATH/TO/DATA/FILE', sep='COLUMN_SEPARATOR', dtype=np.float64)\n",
       "features = tpot_data.drop('target', axis=1)\n",
       "training_features, testing_features, training_target, testing_target = \\\n",
       "            train_test_split(features, tpot_data['target'], random_state=42)\n",
       "\n",
       "imputer = SimpleImputer(strategy=\"median\")\n",
       "imputer.fit(training_features)\n",
       "training_features = imputer.transform(training_features)\n",
       "testing_features = imputer.transform(testing_features)\n",
       "\n",
       "# Average CV score on the training set was: 0.7948519948519949\n",
       "exported_pipeline = make_pipeline(\n",
       "    Nystroem(gamma=0.7000000000000001, kernel=\"additive_chi2\", n_components=1),\n",
       "    XGBClassifier(learning_rate=0.01, max_depth=6, min_child_weight=16, n_estimators=100, n_jobs=1, subsample=0.8500000000000001, verbosity=0)\n",
       ")\n",
       "# Fix random state for all the steps in exported pipeline\n",
       "set_param_recursive(exported_pipeline.steps, 'random_state', 42)\n",
       "\n",
       "exported_pipeline.fit(training_features, training_target)\n",
       "results = exported_pipeline.predict(testing_features)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import Code\n",
    "\n",
    "Code('tpot_churn_pipeline.py')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "c446fa38",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>pre { line-height: 125%; }\n",
       "td.linenos .normal { color: inherit; background-color: transparent; padding-left: 5px; padding-right: 5px; }\n",
       "span.linenos { color: inherit; background-color: transparent; padding-left: 5px; padding-right: 5px; }\n",
       "td.linenos .special { color: #000000; background-color: #ffffc0; padding-left: 5px; padding-right: 5px; }\n",
       "span.linenos.special { color: #000000; background-color: #ffffc0; padding-left: 5px; padding-right: 5px; }\n",
       ".output_html .hll { background-color: #ffffcc }\n",
       ".output_html { background: #f8f8f8; }\n",
       ".output_html .c { color: #3D7B7B; font-style: italic } /* Comment */\n",
       ".output_html .err { border: 1px solid #FF0000 } /* Error */\n",
       ".output_html .k { color: #008000; font-weight: bold } /* Keyword */\n",
       ".output_html .o { color: #666666 } /* Operator */\n",
       ".output_html .ch { color: #3D7B7B; font-style: italic } /* Comment.Hashbang */\n",
       ".output_html .cm { color: #3D7B7B; font-style: italic } /* Comment.Multiline */\n",
       ".output_html .cp { color: #9C6500 } /* Comment.Preproc */\n",
       ".output_html .cpf { color: #3D7B7B; font-style: italic } /* Comment.PreprocFile */\n",
       ".output_html .c1 { color: #3D7B7B; font-style: italic } /* Comment.Single */\n",
       ".output_html .cs { color: #3D7B7B; font-style: italic } /* Comment.Special */\n",
       ".output_html .gd { color: #A00000 } /* Generic.Deleted */\n",
       ".output_html .ge { font-style: italic } /* Generic.Emph */\n",
       ".output_html .gr { color: #E40000 } /* Generic.Error */\n",
       ".output_html .gh { color: #000080; font-weight: bold } /* Generic.Heading */\n",
       ".output_html .gi { color: #008400 } /* Generic.Inserted */\n",
       ".output_html .go { color: #717171 } /* Generic.Output */\n",
       ".output_html .gp { color: #000080; font-weight: bold } /* Generic.Prompt */\n",
       ".output_html .gs { font-weight: bold } /* Generic.Strong */\n",
       ".output_html .gu { color: #800080; font-weight: bold } /* Generic.Subheading */\n",
       ".output_html .gt { color: #0044DD } /* Generic.Traceback */\n",
       ".output_html .kc { color: #008000; font-weight: bold } /* Keyword.Constant */\n",
       ".output_html .kd { color: #008000; font-weight: bold } /* Keyword.Declaration */\n",
       ".output_html .kn { color: #008000; font-weight: bold } /* Keyword.Namespace */\n",
       ".output_html .kp { color: #008000 } /* Keyword.Pseudo */\n",
       ".output_html .kr { color: #008000; font-weight: bold } /* Keyword.Reserved */\n",
       ".output_html .kt { color: #B00040 } /* Keyword.Type */\n",
       ".output_html .m { color: #666666 } /* Literal.Number */\n",
       ".output_html .s { color: #BA2121 } /* Literal.String */\n",
       ".output_html .na { color: #687822 } /* Name.Attribute */\n",
       ".output_html .nb { color: #008000 } /* Name.Builtin */\n",
       ".output_html .nc { color: #0000FF; font-weight: bold } /* Name.Class */\n",
       ".output_html .no { color: #880000 } /* Name.Constant */\n",
       ".output_html .nd { color: #AA22FF } /* Name.Decorator */\n",
       ".output_html .ni { color: #717171; font-weight: bold } /* Name.Entity */\n",
       ".output_html .ne { color: #CB3F38; font-weight: bold } /* Name.Exception */\n",
       ".output_html .nf { color: #0000FF } /* Name.Function */\n",
       ".output_html .nl { color: #767600 } /* Name.Label */\n",
       ".output_html .nn { color: #0000FF; font-weight: bold } /* Name.Namespace */\n",
       ".output_html .nt { color: #008000; font-weight: bold } /* Name.Tag */\n",
       ".output_html .nv { color: #19177C } /* Name.Variable */\n",
       ".output_html .ow { color: #AA22FF; font-weight: bold } /* Operator.Word */\n",
       ".output_html .w { color: #bbbbbb } /* Text.Whitespace */\n",
       ".output_html .mb { color: #666666 } /* Literal.Number.Bin */\n",
       ".output_html .mf { color: #666666 } /* Literal.Number.Float */\n",
       ".output_html .mh { color: #666666 } /* Literal.Number.Hex */\n",
       ".output_html .mi { color: #666666 } /* Literal.Number.Integer */\n",
       ".output_html .mo { color: #666666 } /* Literal.Number.Oct */\n",
       ".output_html .sa { color: #BA2121 } /* Literal.String.Affix */\n",
       ".output_html .sb { color: #BA2121 } /* Literal.String.Backtick */\n",
       ".output_html .sc { color: #BA2121 } /* Literal.String.Char */\n",
       ".output_html .dl { color: #BA2121 } /* Literal.String.Delimiter */\n",
       ".output_html .sd { color: #BA2121; font-style: italic } /* Literal.String.Doc */\n",
       ".output_html .s2 { color: #BA2121 } /* Literal.String.Double */\n",
       ".output_html .se { color: #AA5D1F; font-weight: bold } /* Literal.String.Escape */\n",
       ".output_html .sh { color: #BA2121 } /* Literal.String.Heredoc */\n",
       ".output_html .si { color: #A45A77; font-weight: bold } /* Literal.String.Interpol */\n",
       ".output_html .sx { color: #008000 } /* Literal.String.Other */\n",
       ".output_html .sr { color: #A45A77 } /* Literal.String.Regex */\n",
       ".output_html .s1 { color: #BA2121 } /* Literal.String.Single */\n",
       ".output_html .ss { color: #19177C } /* Literal.String.Symbol */\n",
       ".output_html .bp { color: #008000 } /* Name.Builtin.Pseudo */\n",
       ".output_html .fm { color: #0000FF } /* Name.Function.Magic */\n",
       ".output_html .vc { color: #19177C } /* Name.Variable.Class */\n",
       ".output_html .vg { color: #19177C } /* Name.Variable.Global */\n",
       ".output_html .vi { color: #19177C } /* Name.Variable.Instance */\n",
       ".output_html .vm { color: #19177C } /* Name.Variable.Magic */\n",
       ".output_html .il { color: #666666 } /* Literal.Number.Integer.Long */</style><div class=\"highlight\"><pre><span></span><span class=\"kn\">import</span> <span class=\"nn\">pandas</span> <span class=\"k\">as</span> <span class=\"nn\">pd</span>\n",
       "<span class=\"kn\">from</span> <span class=\"nn\">sklearn.kernel_approximation</span> <span class=\"kn\">import</span> <span class=\"n\">Nystroem</span>\n",
       "<span class=\"kn\">from</span> <span class=\"nn\">sklearn.model_selection</span> <span class=\"kn\">import</span> <span class=\"n\">train_test_split</span>\n",
       "<span class=\"kn\">from</span> <span class=\"nn\">sklearn.pipeline</span> <span class=\"kn\">import</span> <span class=\"n\">make_pipeline</span>\n",
       "<span class=\"kn\">from</span> <span class=\"nn\">xgboost</span> <span class=\"kn\">import</span> <span class=\"n\">XGBClassifier</span>\n",
       "<span class=\"kn\">from</span> <span class=\"nn\">sklearn.impute</span> <span class=\"kn\">import</span> <span class=\"n\">SimpleImputer</span>\n",
       "<span class=\"kn\">from</span> <span class=\"nn\">tpot.export_utils</span> <span class=\"kn\">import</span> <span class=\"n\">set_param_recursive</span>\n",
       "\n",
       "<span class=\"c1\"># NOTE: Make sure that the outcome column is labeled &#39;target&#39; in the data file</span>\n",
       "<span class=\"n\">tpot_data</span> <span class=\"o\">=</span> <span class=\"n\">pd</span><span class=\"o\">.</span><span class=\"n\">read_csv</span><span class=\"p\">(</span><span class=\"s1\">&#39;WEEK5FIXEDDATA.csv&#39;</span><span class=\"p\">)</span>\n",
       "<span class=\"n\">features</span> <span class=\"o\">=</span> <span class=\"n\">tpot_data</span><span class=\"o\">.</span><span class=\"n\">drop</span><span class=\"p\">(</span><span class=\"s1\">&#39;Churn&#39;</span><span class=\"p\">,</span> <span class=\"n\">axis</span><span class=\"o\">=</span><span class=\"mi\">1</span><span class=\"p\">)</span>\n",
       "<span class=\"n\">training_features</span><span class=\"p\">,</span> <span class=\"n\">testing_features</span><span class=\"p\">,</span> <span class=\"n\">training_target</span><span class=\"p\">,</span> <span class=\"n\">testing_target</span> <span class=\"o\">=</span> \\\n",
       "            <span class=\"n\">train_test_split</span><span class=\"p\">(</span><span class=\"n\">features</span><span class=\"p\">,</span> <span class=\"n\">tpot_data</span><span class=\"p\">[</span><span class=\"s1\">&#39;Churn&#39;</span><span class=\"p\">],</span> <span class=\"n\">random_state</span><span class=\"o\">=</span><span class=\"mi\">42</span><span class=\"p\">)</span>\n",
       "\n",
       "<span class=\"n\">imputer</span> <span class=\"o\">=</span> <span class=\"n\">SimpleImputer</span><span class=\"p\">(</span><span class=\"n\">strategy</span><span class=\"o\">=</span><span class=\"s2\">&quot;median&quot;</span><span class=\"p\">)</span>\n",
       "<span class=\"n\">imputer</span><span class=\"o\">.</span><span class=\"n\">fit</span><span class=\"p\">(</span><span class=\"n\">training_features</span><span class=\"p\">)</span>\n",
       "<span class=\"n\">training_features</span> <span class=\"o\">=</span> <span class=\"n\">imputer</span><span class=\"o\">.</span><span class=\"n\">transform</span><span class=\"p\">(</span><span class=\"n\">training_features</span><span class=\"p\">)</span>\n",
       "<span class=\"n\">testing_features</span> <span class=\"o\">=</span> <span class=\"n\">imputer</span><span class=\"o\">.</span><span class=\"n\">transform</span><span class=\"p\">(</span><span class=\"n\">testing_features</span><span class=\"p\">)</span>\n",
       "\n",
       "<span class=\"c1\"># Average CV score on the training set was: 0.7948519948519949</span>\n",
       "<span class=\"n\">exported_pipeline</span> <span class=\"o\">=</span> <span class=\"n\">make_pipeline</span><span class=\"p\">(</span>\n",
       "    <span class=\"n\">Nystroem</span><span class=\"p\">(</span><span class=\"n\">gamma</span><span class=\"o\">=</span><span class=\"mf\">0.7000000000000001</span><span class=\"p\">,</span> <span class=\"n\">kernel</span><span class=\"o\">=</span><span class=\"s2\">&quot;additive_chi2&quot;</span><span class=\"p\">,</span> <span class=\"n\">n_components</span><span class=\"o\">=</span><span class=\"mi\">1</span><span class=\"p\">),</span>\n",
       "    <span class=\"n\">XGBClassifier</span><span class=\"p\">(</span><span class=\"n\">learning_rate</span><span class=\"o\">=</span><span class=\"mf\">0.01</span><span class=\"p\">,</span> <span class=\"n\">max_depth</span><span class=\"o\">=</span><span class=\"mi\">6</span><span class=\"p\">,</span> <span class=\"n\">min_child_weight</span><span class=\"o\">=</span><span class=\"mi\">16</span><span class=\"p\">,</span> <span class=\"n\">n_estimators</span><span class=\"o\">=</span><span class=\"mi\">100</span><span class=\"p\">,</span> <span class=\"n\">n_jobs</span><span class=\"o\">=</span><span class=\"mi\">1</span><span class=\"p\">,</span> <span class=\"n\">subsample</span><span class=\"o\">=</span><span class=\"mf\">0.8500000000000001</span><span class=\"p\">,</span> <span class=\"n\">verbosity</span><span class=\"o\">=</span><span class=\"mi\">0</span><span class=\"p\">)</span>\n",
       "<span class=\"p\">)</span>\n",
       "<span class=\"c1\"># Fix random state for all the steps in exported pipeline</span>\n",
       "<span class=\"n\">set_param_recursive</span><span class=\"p\">(</span><span class=\"n\">exported_pipeline</span><span class=\"o\">.</span><span class=\"n\">steps</span><span class=\"p\">,</span> <span class=\"s1\">&#39;random_state&#39;</span><span class=\"p\">,</span> <span class=\"mi\">42</span><span class=\"p\">)</span>\n",
       "\n",
       "<span class=\"n\">exported_pipeline</span><span class=\"o\">.</span><span class=\"n\">fit</span><span class=\"p\">(</span><span class=\"n\">training_features</span><span class=\"p\">,</span> <span class=\"n\">training_target</span><span class=\"p\">)</span>\n",
       "<span class=\"n\">results</span> <span class=\"o\">=</span> <span class=\"n\">exported_pipeline</span><span class=\"o\">.</span><span class=\"n\">predict</span><span class=\"p\">(</span><span class=\"n\">testing_features</span><span class=\"p\">)</span>\n",
       "</pre></div>\n"
      ],
      "text/latex": [
       "\\begin{Verbatim}[commandchars=\\\\\\{\\}]\n",
       "\\PY{k+kn}{import} \\PY{n+nn}{pandas} \\PY{k}{as} \\PY{n+nn}{pd}\n",
       "\\PY{k+kn}{from} \\PY{n+nn}{sklearn}\\PY{n+nn}{.}\\PY{n+nn}{kernel\\PYZus{}approximation} \\PY{k+kn}{import} \\PY{n}{Nystroem}\n",
       "\\PY{k+kn}{from} \\PY{n+nn}{sklearn}\\PY{n+nn}{.}\\PY{n+nn}{model\\PYZus{}selection} \\PY{k+kn}{import} \\PY{n}{train\\PYZus{}test\\PYZus{}split}\n",
       "\\PY{k+kn}{from} \\PY{n+nn}{sklearn}\\PY{n+nn}{.}\\PY{n+nn}{pipeline} \\PY{k+kn}{import} \\PY{n}{make\\PYZus{}pipeline}\n",
       "\\PY{k+kn}{from} \\PY{n+nn}{xgboost} \\PY{k+kn}{import} \\PY{n}{XGBClassifier}\n",
       "\\PY{k+kn}{from} \\PY{n+nn}{sklearn}\\PY{n+nn}{.}\\PY{n+nn}{impute} \\PY{k+kn}{import} \\PY{n}{SimpleImputer}\n",
       "\\PY{k+kn}{from} \\PY{n+nn}{tpot}\\PY{n+nn}{.}\\PY{n+nn}{export\\PYZus{}utils} \\PY{k+kn}{import} \\PY{n}{set\\PYZus{}param\\PYZus{}recursive}\n",
       "\n",
       "\\PY{c+c1}{\\PYZsh{} NOTE: Make sure that the outcome column is labeled \\PYZsq{}target\\PYZsq{} in the data file}\n",
       "\\PY{n}{tpot\\PYZus{}data} \\PY{o}{=} \\PY{n}{pd}\\PY{o}{.}\\PY{n}{read\\PYZus{}csv}\\PY{p}{(}\\PY{l+s+s1}{\\PYZsq{}}\\PY{l+s+s1}{WEEK5FIXEDDATA.csv}\\PY{l+s+s1}{\\PYZsq{}}\\PY{p}{)}\n",
       "\\PY{n}{features} \\PY{o}{=} \\PY{n}{tpot\\PYZus{}data}\\PY{o}{.}\\PY{n}{drop}\\PY{p}{(}\\PY{l+s+s1}{\\PYZsq{}}\\PY{l+s+s1}{Churn}\\PY{l+s+s1}{\\PYZsq{}}\\PY{p}{,} \\PY{n}{axis}\\PY{o}{=}\\PY{l+m+mi}{1}\\PY{p}{)}\n",
       "\\PY{n}{training\\PYZus{}features}\\PY{p}{,} \\PY{n}{testing\\PYZus{}features}\\PY{p}{,} \\PY{n}{training\\PYZus{}target}\\PY{p}{,} \\PY{n}{testing\\PYZus{}target} \\PY{o}{=} \\PYZbs{}\n",
       "            \\PY{n}{train\\PYZus{}test\\PYZus{}split}\\PY{p}{(}\\PY{n}{features}\\PY{p}{,} \\PY{n}{tpot\\PYZus{}data}\\PY{p}{[}\\PY{l+s+s1}{\\PYZsq{}}\\PY{l+s+s1}{Churn}\\PY{l+s+s1}{\\PYZsq{}}\\PY{p}{]}\\PY{p}{,} \\PY{n}{random\\PYZus{}state}\\PY{o}{=}\\PY{l+m+mi}{42}\\PY{p}{)}\n",
       "\n",
       "\\PY{n}{imputer} \\PY{o}{=} \\PY{n}{SimpleImputer}\\PY{p}{(}\\PY{n}{strategy}\\PY{o}{=}\\PY{l+s+s2}{\\PYZdq{}}\\PY{l+s+s2}{median}\\PY{l+s+s2}{\\PYZdq{}}\\PY{p}{)}\n",
       "\\PY{n}{imputer}\\PY{o}{.}\\PY{n}{fit}\\PY{p}{(}\\PY{n}{training\\PYZus{}features}\\PY{p}{)}\n",
       "\\PY{n}{training\\PYZus{}features} \\PY{o}{=} \\PY{n}{imputer}\\PY{o}{.}\\PY{n}{transform}\\PY{p}{(}\\PY{n}{training\\PYZus{}features}\\PY{p}{)}\n",
       "\\PY{n}{testing\\PYZus{}features} \\PY{o}{=} \\PY{n}{imputer}\\PY{o}{.}\\PY{n}{transform}\\PY{p}{(}\\PY{n}{testing\\PYZus{}features}\\PY{p}{)}\n",
       "\n",
       "\\PY{c+c1}{\\PYZsh{} Average CV score on the training set was: 0.7948519948519949}\n",
       "\\PY{n}{exported\\PYZus{}pipeline} \\PY{o}{=} \\PY{n}{make\\PYZus{}pipeline}\\PY{p}{(}\n",
       "    \\PY{n}{Nystroem}\\PY{p}{(}\\PY{n}{gamma}\\PY{o}{=}\\PY{l+m+mf}{0.7000000000000001}\\PY{p}{,} \\PY{n}{kernel}\\PY{o}{=}\\PY{l+s+s2}{\\PYZdq{}}\\PY{l+s+s2}{additive\\PYZus{}chi2}\\PY{l+s+s2}{\\PYZdq{}}\\PY{p}{,} \\PY{n}{n\\PYZus{}components}\\PY{o}{=}\\PY{l+m+mi}{1}\\PY{p}{)}\\PY{p}{,}\n",
       "    \\PY{n}{XGBClassifier}\\PY{p}{(}\\PY{n}{learning\\PYZus{}rate}\\PY{o}{=}\\PY{l+m+mf}{0.01}\\PY{p}{,} \\PY{n}{max\\PYZus{}depth}\\PY{o}{=}\\PY{l+m+mi}{6}\\PY{p}{,} \\PY{n}{min\\PYZus{}child\\PYZus{}weight}\\PY{o}{=}\\PY{l+m+mi}{16}\\PY{p}{,} \\PY{n}{n\\PYZus{}estimators}\\PY{o}{=}\\PY{l+m+mi}{100}\\PY{p}{,} \\PY{n}{n\\PYZus{}jobs}\\PY{o}{=}\\PY{l+m+mi}{1}\\PY{p}{,} \\PY{n}{subsample}\\PY{o}{=}\\PY{l+m+mf}{0.8500000000000001}\\PY{p}{,} \\PY{n}{verbosity}\\PY{o}{=}\\PY{l+m+mi}{0}\\PY{p}{)}\n",
       "\\PY{p}{)}\n",
       "\\PY{c+c1}{\\PYZsh{} Fix random state for all the steps in exported pipeline}\n",
       "\\PY{n}{set\\PYZus{}param\\PYZus{}recursive}\\PY{p}{(}\\PY{n}{exported\\PYZus{}pipeline}\\PY{o}{.}\\PY{n}{steps}\\PY{p}{,} \\PY{l+s+s1}{\\PYZsq{}}\\PY{l+s+s1}{random\\PYZus{}state}\\PY{l+s+s1}{\\PYZsq{}}\\PY{p}{,} \\PY{l+m+mi}{42}\\PY{p}{)}\n",
       "\n",
       "\\PY{n}{exported\\PYZus{}pipeline}\\PY{o}{.}\\PY{n}{fit}\\PY{p}{(}\\PY{n}{training\\PYZus{}features}\\PY{p}{,} \\PY{n}{training\\PYZus{}target}\\PY{p}{)}\n",
       "\\PY{n}{results} \\PY{o}{=} \\PY{n}{exported\\PYZus{}pipeline}\\PY{o}{.}\\PY{n}{predict}\\PY{p}{(}\\PY{n}{testing\\PYZus{}features}\\PY{p}{)}\n",
       "\\end{Verbatim}\n"
      ],
      "text/plain": [
       "import pandas as pd\n",
       "from sklearn.kernel_approximation import Nystroem\n",
       "from sklearn.model_selection import train_test_split\n",
       "from sklearn.pipeline import make_pipeline\n",
       "from xgboost import XGBClassifier\n",
       "from sklearn.impute import SimpleImputer\n",
       "from tpot.export_utils import set_param_recursive\n",
       "\n",
       "# NOTE: Make sure that the outcome column is labeled 'target' in the data file\n",
       "tpot_data = pd.read_csv('WEEK5FIXEDDATA.csv')\n",
       "features = tpot_data.drop('Churn', axis=1)\n",
       "training_features, testing_features, training_target, testing_target = \\\n",
       "            train_test_split(features, tpot_data['Churn'], random_state=42)\n",
       "\n",
       "imputer = SimpleImputer(strategy=\"median\")\n",
       "imputer.fit(training_features)\n",
       "training_features = imputer.transform(training_features)\n",
       "testing_features = imputer.transform(testing_features)\n",
       "\n",
       "# Average CV score on the training set was: 0.7948519948519949\n",
       "exported_pipeline = make_pipeline(\n",
       "    Nystroem(gamma=0.7000000000000001, kernel=\"additive_chi2\", n_components=1),\n",
       "    XGBClassifier(learning_rate=0.01, max_depth=6, min_child_weight=16, n_estimators=100, n_jobs=1, subsample=0.8500000000000001, verbosity=0)\n",
       ")\n",
       "# Fix random state for all the steps in exported pipeline\n",
       "set_param_recursive(exported_pipeline.steps, 'random_state', 42)\n",
       "\n",
       "exported_pipeline.fit(training_features, training_target)\n",
       "results = exported_pipeline.predict(testing_features)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Code('tpot_churn_pipeline.py')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "560f99c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 ... 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "%run tpot_churn_pipeline.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "3543ec3d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, ..., 0, 0, 0])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c49db562",
   "metadata": {},
   "source": [
    "# Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9533a1cd",
   "metadata": {},
   "source": [
    "This assingment was rather interesting. The first part of the data manipulation is the same which is now easier to follow. At first I found this a bit complicated and confusing. However, now I feel much better about it. The second part of this assignment was really nice and straightforward. If I am honest, I do not like working out of the notebook setting, I feel it is something that would not be done in a normal work setting. The transitioning this week in to an edtior and GIT is amazing. Also, I found the transition into the python code bringing everything together, this was the coolest part of the assignment. We have learned many commands and they all convert into a python file where we are able to run the py code."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
